{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aashitapatwari/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:93: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/tweets.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5f9d41319110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-5f9d41319110>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# read the tweets and its labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/tweets.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feature_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/tweets.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_vector_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/labels.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5f9d41319110>\u001b[0m in \u001b[0;36mextract_dictionary\u001b[0;34m(infile)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rU'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;31m### ========== TODO : START ========== ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# part 1a: process each line to populate word_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/tweets.txt'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author      : Yi-Chieh Wu, Sriram Sankararman\n",
    "Description : Twitter\n",
    "\"\"\"\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# !!! MAKE SURE TO USE SVC.decision_function(X), NOT SVC.predict(X) !!!\n",
    "# (this makes ``continuous-valued'' predictions)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "######################################################################\n",
    "# functions -- input/output\n",
    "######################################################################\n",
    "\n",
    "def read_vector_file(fname):\n",
    "    \"\"\"\n",
    "    Reads and returns a vector from a file.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        fname  -- string, filename\n",
    "        \n",
    "    Returns\n",
    "    --------------------\n",
    "        labels -- numpy array of shape (n,)\n",
    "                    n is the number of non-blank lines in the text file\n",
    "    \"\"\"\n",
    "    return np.genfromtxt(fname)\n",
    "\n",
    "\n",
    "def write_label_answer(vec, outfile):\n",
    "    \"\"\"\n",
    "    Writes your label vector to the given file.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        vec     -- numpy array of shape (n,) or (n,1), predicted scores\n",
    "        outfile -- string, output filename\n",
    "    \"\"\"\n",
    "    \n",
    "    # for this project, you should predict 70 labels\n",
    "    if(vec.shape[0] != 70):\n",
    "        print(\"Error - output vector should have 70 rows.\")\n",
    "        print(\"Aborting write.\")\n",
    "        return\n",
    "    \n",
    "    np.savetxt(outfile, vec)    \n",
    "\n",
    "\n",
    "######################################################################\n",
    "# functions -- feature extraction\n",
    "######################################################################\n",
    "\n",
    "def extract_words(input_string):\n",
    "    \"\"\"\n",
    "    Processes the input_string, separating it into \"words\" based on the presence\n",
    "    of spaces, and separating punctuation marks into their own words.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        input_string -- string of characters\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        words        -- list of lowercase \"words\"\n",
    "    \"\"\"\n",
    "    \n",
    "    for c in punctuation :\n",
    "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
    "    return input_string.lower().split()\n",
    "\n",
    "\n",
    "def extract_dictionary(infile):\n",
    "    \"\"\"\n",
    "    Given a filename, reads the text file and builds a dictionary of unique\n",
    "    words/punctuations.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        infile    -- string, filename\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        word_list -- dictionary, (key, value) pairs are (word, index)\n",
    "    \"\"\"\n",
    "    \n",
    "    word_list = {}\n",
    "    with open(infile, 'rU') as fid :\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part 1a: process each line to populate word_list\n",
    "        pass\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def extract_feature_vectors(infile, word_list):\n",
    "    \"\"\"\n",
    "    Produces a bag-of-words representation of a text file specified by the\n",
    "    filename infile based on the dictionary word_list.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        infile         -- string, filename\n",
    "        word_list      -- dictionary, (key, value) pairs are (word, index)\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        feature_matrix -- numpy array of shape (n,d)\n",
    "                          boolean (0,1) array indicating word presence in a string\n",
    "                            n is the number of non-blank lines in the text file\n",
    "                            d is the number of unique words in the text file\n",
    "    \"\"\"\n",
    "    \n",
    "    num_lines = sum(1 for line in open(infile,'rU'))\n",
    "    num_words = len(word_list)\n",
    "    feature_matrix = np.zeros((num_lines, num_words))\n",
    "    \n",
    "    with open(infile, 'rU') as fid :\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part 1b: process each line to populate feature_matrix\n",
    "        pass\n",
    "        ### ========== TODO : END ========== ###\n",
    "        \n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# functions -- evaluation\n",
    "######################################################################\n",
    "\n",
    "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Calculates the performance metric based on the agreement between the \n",
    "    true labels and the predicted labels.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        y_true -- numpy array of shape (n,), known labels\n",
    "        y_pred -- numpy array of shape (n,), (continuous-valued) predictions\n",
    "        metric -- string, option used to select the performance measure\n",
    "                  options: 'accuracy', 'f1-score', 'auroc', 'precision',\n",
    "                           'sensitivity', 'specificity'        \n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        score  -- float, performance score\n",
    "    \"\"\"\n",
    "    # map continuous-valued predictions to binary labels\n",
    "    y_label = np.sign(y_pred)\n",
    "    y_label[y_label==0] = 1\n",
    "    \n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 2a: compute classifier performance\n",
    "    return 0\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def cv_performance(clf, X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Splits the data, X and y, into k-folds and runs k-fold cross-validation.\n",
    "    Trains classifier on k-1 folds and tests on the remaining fold.\n",
    "    Calculates the k-fold cross-validation performance metric for classifier\n",
    "    by averaging the performance across folds.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf    -- classifier (instance of SVC)\n",
    "        X      -- numpy array of shape (n,d), feature vectors\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- cross_validation.KFold or cross_validation.StratifiedKFold\n",
    "        metric -- string, option used to select performance measure\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        score   -- float, average cross-validation performance across k folds\n",
    "    \"\"\"\n",
    "    \n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 2b: compute average cross-validation performance    \n",
    "    return 0\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def select_param_linear(X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameter of a linear-kernel SVM,\n",
    "    calculating the k-fold CV performance for each setting, then selecting the\n",
    "    hyperparameter that 'maximize' the average k-fold CV performance.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        X      -- numpy array of shape (n,d), feature vectors\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- cross_validation.KFold or cross_validation.StratifiedKFold\n",
    "        metric -- string, option used to select performance measure\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        C -- float, optimal parameter value for linear-kernel SVM\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Linear SVM Hyperparameter Selection based on ', str(metric), ':')\n",
    "    C_range = 10.0 ** np.arange(-3, 3)\n",
    "    \n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 2c: select optimal hyperparameter using cross-validation\n",
    "    return 1.0\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def select_param_rbf(X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameters of an RBF-kernel SVM,\n",
    "    calculating the k-fold CV performance for each setting, then selecting the\n",
    "    hyperparameters that 'maximize' the average k-fold CV performance.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        X       -- numpy array of shape (n,d), feature vectors\n",
    "                     n = number of examples\n",
    "                     d = number of features\n",
    "        y       -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- cross_validation.KFold or cross_validation.StratifiedKFold\n",
    "        metric  -- string, option used to select performance measure\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        gamma, C -- tuple of floats, optimal parameter values for an RBF-kernel SVM\n",
    "    \"\"\"\n",
    "    \n",
    "    print('RBF SVM Hyperparameter Selection based on ', str(metric), ':')\n",
    "    \n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 3b: create grid, then select optimal hyperparameters using cross-validation\n",
    "    return 0.0, 1.0\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def performance_test(clf, X, y, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Estimates the performance of the classifier using the 95% CI.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf          -- classifier (instance of SVC)\n",
    "                          [already fit to data]\n",
    "        X            -- numpy array of shape (n,d), feature vectors of test set\n",
    "                          n = number of examples\n",
    "                          d = number of features\n",
    "        y            -- numpy array of shape (n,), binary labels {1,-1} of test set\n",
    "        metric       -- string, option used to select performance measure\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "        score        -- float, classifier performance\n",
    "    \"\"\"\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 4b: return performance on test data by first computing predictions and then calling performance\n",
    "\n",
    "    score = 0        \n",
    "    return score\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# main\n",
    "######################################################################\n",
    " \n",
    "def main() :\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    # read the tweets and its labels   \n",
    "    dictionary = extract_dictionary('../data/tweets.txt')\n",
    "    X = extract_feature_vectors('../data/tweets.txt', dictionary)\n",
    "    y = read_vector_file('../data/labels.txt')\n",
    "    \n",
    "    metric_list = [\"accuracy\", \"f1_score\", \"auroc\", \"precision\", \"sensitivity\", \"specificity\"]\n",
    "    \n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 1c: split data into training (training + cross-validation) and testing set\n",
    "    \n",
    "    # part 2b: create stratified folds (5-fold CV)\n",
    "    \n",
    "    # part 2d: for each metric, select optimal hyperparameter for linear-kernel SVM using CV\n",
    "    \n",
    "    # part 3c: for each metric, select optimal hyperparameter for RBF-SVM using CV\n",
    "    \n",
    "    # part 4a: train linear- and RBF-kernel SVMs with selected hyperparameters\n",
    "    \n",
    "    # part 4c: report performance on test data\n",
    "    \n",
    "    ### ========== TODO : END ========== ###\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\" :\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
